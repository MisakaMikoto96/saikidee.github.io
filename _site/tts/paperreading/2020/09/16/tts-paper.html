<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">
<link rel="stylesheet" href="/assets/css/style.css">
<title>语音合成论文阅读目录</title>
<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>语音合成论文阅读目录 | Your awesome title</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="语音合成论文阅读目录" />
<meta name="author" content="GitHub User" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="收录和分享一些语音合成领域论文阅读清单, 包括前端、声学模型、声码器、VC、情感合成、风格迁移、歌声合成等内容。" />
<meta property="og:description" content="收录和分享一些语音合成领域论文阅读清单, 包括前端、声学模型、声码器、VC、情感合成、风格迁移、歌声合成等内容。" />
<link rel="canonical" href="http://localhost:4000/tts/paperreading/2020/09/16/tts-paper.html" />
<meta property="og:url" content="http://localhost:4000/tts/paperreading/2020/09/16/tts-paper.html" />
<meta property="og:site_name" content="Your awesome title" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-16T13:51:36+08:00" />
<script type="application/ld+json">
{"description":"收录和分享一些语音合成领域论文阅读清单, 包括前端、声学模型、声码器、VC、情感合成、风格迁移、歌声合成等内容。","author":{"@type":"Person","name":"GitHub User"},"@type":"BlogPosting","url":"http://localhost:4000/tts/paperreading/2020/09/16/tts-paper.html","headline":"语音合成论文阅读目录","dateModified":"2020-09-16T13:51:36+08:00","datePublished":"2020-09-16T13:51:36+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/tts/paperreading/2020/09/16/tts-paper.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
</head>

<body>
  <main class="container">
    <section class="about">
      <a href="/">
        
        <img src="/assets/saikiprofile.png" alt="Saiki 贺雯迪" />
        
      </a>
      <h2 id="title">
        <a href="/">Saiki 贺雯迪</a>
      </h2>
      <p class="tagline">Algorithm Engineer in TTS</p>
      <ul class="social"><a href="https://github.com/samarsault" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://www.linkedin.com/in/samarsault" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><a href="https://twitter.com/samarsault" target="_blank">
          <li>
            <i class="icon-twitter-squared"></i>
          </li>
        </a></ul><p>&copy;
        2020</p><div>
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" id="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
      <script type="text/javascript" src="/assets/js/darkmode.js"></script></section>
    <section class="content">
      <div class="post-container">
  <a class="post-link" href="/tts/paperreading/2020/09/16/tts-paper.html">
    <h2 class="post-title">语音合成论文阅读目录</h2>
  </a>
  <div class="post-meta">
    <div class="post-date"><i class="icon-calendar"></i>Sep 16, 2020</div><ul class="post-categories"><li>TTS</li><li>PaperReading</li></ul></div>
  <div class="post">
    <p>收录和分享一些语音合成领域论文阅读清单, 包括前端、声学模型、声码器、VC、情感合成、风格迁移、歌声合成等内容。</p>

<h1 id="frontend">Frontend</h1>
<h2 id="多音字">多音字</h2>

<p><a href="https://www.isca-speech.org/archive/Interspeech_2019/pdfs/2292.pdf">Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-trained BERT</a></p>

<p><a href="https://arxiv.org/abs/2004.03136">g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin Chinese Based on a New Open Benchmark Dataset</a></p>

<h2 id="韵律">韵律</h2>

<p>## 
<strong>__</strong><em>__</em></p>

<h1 id="vocoder">Vocoder</h1>
<p><strong>WavenNet</strong></p>

<p><strong>WaveGlow</strong></p>

<p><strong>WaveRNN</strong></p>

<p><strong>FastSpeech1</strong></p>

<p><strong>FastSpeech2</strong></p>

<p><strong>Mel-Gan</strong></p>

<p><strong>Multi-band MelGan</strong></p>

<p><strong>Parallel WaveGan</strong></p>

<hr />

<h1 id="acoustic-model">Acoustic Model</h1>

<p><strong>Tacotron</strong>：<a href="https://arxiv.org/pdf/1703.10135.pdf">Tacotron: Towards End-to-End Speech Synthesis</a></p>

<p><strong>Tacotron2</strong>： <a href="https://arxiv.org/pdf/1712.05884.pdf">Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a></p>

<p><strong>Transformer-TTS</strong>：<a href="https://arxiv.org/pdf/1809.08895.pdf">Neural Speech Synthesis with Transformer Network</a></p>

<p><strong>Durian</strong> <a href="https://arxiv.org/abs/1909.01700.pdf">DurIAN: Duration Informed Attention Network For Multimodal Synthesis</a></p>

<p><strong>AdaDurain</strong> <a href="https://arxiv.org/pdf/2005.05642.pdf">AdaDurIAN: Few-shot Adaptation for Neural Text-to-Speech with DurIAN</a></p>

<hr />

<h1 id="expressive-tts">Expressive TTS</h1>

<hr />

<h1 id="sing-synthesis">Sing Synthesis</h1>

<hr />

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

  </div></div>

    </section>
  </main>
  <script src="/assets/js/simple-jekyll-search.min.js"></script>
  <script src="/assets/js/search.js"></script>
  
</body>

</html>
