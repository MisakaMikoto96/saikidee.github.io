<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">
<link rel="stylesheet" href="/assets/css/style.css">
<title>语音合成论文阅读目录</title>
<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>语音合成论文阅读目录 | Your awesome title</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="语音合成论文阅读目录" />
<meta name="author" content="GitHub User" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="收录和分享一些语音合成领域论文阅读清单, 包括前端、声学模型、声码器、VC、情感合成、风格迁移、歌声合成等内容。" />
<meta property="og:description" content="收录和分享一些语音合成领域论文阅读清单, 包括前端、声学模型、声码器、VC、情感合成、风格迁移、歌声合成等内容。" />
<meta property="og:site_name" content="Your awesome title" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-16T13:51:36+08:00" />
<script type="application/ld+json">
{"description":"收录和分享一些语音合成领域论文阅读清单, 包括前端、声学模型、声码器、VC、情感合成、风格迁移、歌声合成等内容。","author":{"@type":"Person","name":"GitHub User"},"@type":"BlogPosting","url":"/tts/paperreading/2020/09/16/tts-paper.html","headline":"语音合成论文阅读目录","dateModified":"2020-09-16T13:51:36+08:00","datePublished":"2020-09-16T13:51:36+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/tts/paperreading/2020/09/16/tts-paper.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
</head>

<body>
  <main class="container">
    <section class="about">
      <a href="/">
        
        <img src="/assets/saikiprofile.png" alt="Saiki 贺雯迪" />
        
      </a>
      <h2 id="title">
        <a href="/">Saiki 贺雯迪</a>
      </h2>
      <p class="tagline">Algorithm Engineer in TTS</p>
      <ul class="social"><a href="https://github.com/MisakaMikoto96" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://www.linkedin.com/in/samarsault" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><a href="https://instagram.com/clorisdee_96" target="_blank">
          <li>
            <i class="icon-instagram"></i>
          </li>
        </a></ul><p>&copy;
        2020</p><div>
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" id="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
      <script type="text/javascript" src="/assets/js/darkmode.js"></script></section>
    <section class="content">
      <div class="post-container">
  <a class="post-link" href="/tts/paperreading/2020/09/16/tts-paper.html">
    <h2 class="post-title">语音合成论文阅读目录</h2>
  </a>
  <div class="post-meta">
    <div class="post-date"><i class="icon-calendar"></i>Sep 16, 2020</div><ul class="post-categories"><li>TTS</li><li>PaperReading</li></ul></div>
  <div class="post">
    <p>收录和分享一些语音合成领域论文阅读清单, 包括前端、声学模型、声码器、VC、情感合成、风格迁移、歌声合成等内容。</p>

<h1 id="frontend">Frontend</h1>
<h2 id="多音字">多音字</h2>

<p><a href="https://www.isca-speech.org/archive/Interspeech_2019/pdfs/2292.pdf">Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-trained BERT</a>（2019）</p>

<p><a href="https://arxiv.org/abs/2004.03136">g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin Chinese Based on a New Open Benchmark Dataset</a>（2020）</p>

<h2 id="韵律">韵律</h2>

<hr />

<h1 id="vocoder">Vocoder</h1>
<p><strong>WavenNet</strong> <a href="https://arxiv.org/abs/1712.05884.pdf">Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a>（2017）</p>

<p><strong>WaveGlow</strong> <a href="https://arxiv.org/abs/1811.00002.pdf">WaveGlow: A Flow-based Generative Network for Speech Synthesis</a>（2018）</p>

<p><strong>WaveRNN</strong> <a href="https://arxiv.org/abs/1802.08435.pdf">Efficient Neural Audio Synthesis</a> （2018）</p>

<p><strong>FastSpeech1</strong> <a href="https://arxiv.org/abs/1905.09263.pdf">FastSpeech: Fast, Robust and Controllable Text to Speech</a> （2019）</p>

<p><strong>FastSpeech2</strong> <a href="https://arxiv.org/pdf/2006.04558v3.pdf">FastSpeech 2: Fast and High-Quality End-to-End Text to Speech</a> (2020)</p>

<p><strong>Mel-Gan</strong> <a href="https://arxiv.org/abs/1910.06711.pdf">MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis</a> (2019)</p>

<p><strong>Multi-band MelGan</strong> <a href="https://arxiv.org/pdf/2005.05106.pdf">Multi-band MelGAN: Faster Waveform Generation for High-Quality Text-to-Speech</a> (2020)</p>

<p><strong>Parallel WaveGan</strong> <a href="https://arxiv.org/abs/1909.01700.pdf">DurIAN: Duration Informed Attention Network For Multimodal Synthesis</a> (2019）</p>

<hr />

<h1 id="acoustic-model">Acoustic Model</h1>

<p><strong>Tacotron</strong>：<a href="https://arxiv.org/pdf/1703.10135.pdf">Tacotron: Towards End-to-End Speech Synthesis</a> （2017）</p>

<p><strong>Tacotron2</strong>： <a href="https://arxiv.org/pdf/1712.05884.pdf">Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a> （2017）</p>

<p><strong>Transformer-TTS</strong>：<a href="https://arxiv.org/pdf/1809.08895.pdf">Neural Speech Synthesis with Transformer Network</a> （2018）</p>

<p><strong>Durian</strong> <a href="https://arxiv.org/abs/1909.01700.pdf">DurIAN: Duration Informed Attention Network For Multimodal Synthesis</a> (2019）</p>

<p><strong>AdaDurain</strong> <a href="https://arxiv.org/pdf/2005.05642.pdf">AdaDurIAN: Few-shot Adaptation for Neural Text-to-Speech with DurIAN</a> (2020)</p>

<hr />

<h1 id="expressive-tts-style-transfer--control--disentangle">Expressive TTS (style transfer &amp; control &amp; disentangle)</h1>
<h2 id="gst-based">GST-based</h2>
<p><a href="https://arxiv.org/abs/1909.01700.pdf">DurIAN: Duration Informed Attention Network For Multimodal Synthesis</a> (2019）</p>

<p><a href="https://arxiv.org/abs/1904.02373.pdf">Multi-reference Tacotron by Intercross Training for Style Disentangling,Transfer and Control in Speech Synthesis</a>(2019)</p>

<p><a href="https://arxiv.org/abs/1803.09017.pdf">Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis</a>(2018)</p>

<h2 id="vae-based">VAE-based</h2>
<p><a href="https://arxiv.org/abs/2002.03785.pdf">Fully-hierarchical fine-grained prosody modeling for interpretable speech synthesis</a>(2020)</p>

<p><a href="https://arxiv.org/abs/1906.03402.pdf">Effective Use of Variational Embedding Capacity in Expressive End-to-End Speech Synthesis</a>(2019)</p>

<p><a href="https://arxiv.org/abs/1811.02122.pdf">Robust and fine-grained prosody control of end-to-end speech synthesis</a>(2018)</p>

<p><a href="https://arxiv.org/abs/1810.07217.pdf">Hierarchical Generative Modeling for Controllable Speech Synthesis</a>(2018)</p>

<p><a href="https://arxiv.org/abs/1812.04342.pdf">Learning latent representations for style control and transfer in end-to-end speech synthesis</a>(2018)</p>

<h3 id="advanced">Advanced</h3>
<p><a href="https://arxiv.org/abs/1905.04982.pdf">Learning Hierarchical Priors in VAEs</a>（2019）</p>

<p><a href="https://arxiv.org/abs/1804.03599.pdf">Understanding disentangling in β-VAE</a> (2018)</p>

<p><a href="https://arxiv.org/abs/1810.00597.pdf">Taming vae</a> (2018)</p>

<p><a href="https://openreview.net/pdf?id=Sy2fzU9gl">beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework</a> (2017)</p>

<p><a href="http://proceedings.mlr.press/v84/tomczak18a/tomczak18a.pdf">VAE with a VampPrior</a> (2017)</p>

<p><a href="https://arxiv.org/abs/1711.00464.pdf">Fixing a Broken ELBO</a>(2017)</p>

<p><a href="https://arxiv.org/abs/1606.04934.pdf">Improving Variational Inference with Inverse Autoregressive Flow </a> (2016)</p>

<p><a href="https://arxiv.org/abs/1509.00519.pdf">Importance weighted autoencoders</a>（2015）</p>

<hr />

<h1 id="sing-synthesis">Sing Synthesis</h1>

<hr />

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

  </div></div>

    </section>
  </main>
  <script src="/assets/js/simple-jekyll-search.min.js"></script>
  <script src="/assets/js/search.js"></script>
  
</body>

</html>
